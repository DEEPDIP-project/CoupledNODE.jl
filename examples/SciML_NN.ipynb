{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exploration of SciML (2/2)\n",
    "This notebook is the continuation of the previous exploration. Here, we will try to :\n",
    "**Use a neural closure term to learn the parameters using a priori fitting.**\n",
    "We will explore different implementations of the same problem in the SciML ecosystem:\n",
    "a. **NeuraODE + CoupleNODE**: Our implementation to build a coupled problem and solve it using [NeuralODE](https://docs.sciml.ai/DiffEqFlux/stable/layers/NeuralDELayers/#DiffEqFlux.NeuralODE).\n",
    "b. **ODEProblem + CoupleNODE**: Same as the previous example but using the emblematic implementation of SciML (ODEProblem) instead of NeuralODE.\n",
    "c. **[SplitODE]**(https://docs.sciml.ai/DiffEqDocs/stable/types/split_ode_types/)\n",
    "d.\n",
    "We will benchmark some of the key parts and compare the obtained results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper functions\n",
    "- Helper function to reshape `ODESolution` to our matrices. Returns an object with dimentions `(x, y, n_samples, t)`"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function reshape_ODESolution(ODE_sol, grid)\n",
    "    u = reshape(ODE_sol[1:(grid.N), :, :], grid.nx, grid.ny, size(ODE_sol, 2), :)\n",
    "    v = reshape(ODE_sol[(grid_GS.N + 1):end, :, :], grid.nx, grid.ny, size(ODE_sol, 2), :)\n",
    "    return u, v\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Helper function to plot a Gray-Scott heatmap"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function GS_heatmap(data; title = \"\", color = :reds)\n",
    "    return heatmap(data,\n",
    "        axis = false,\n",
    "        cbar = false,\n",
    "        aspect_ratio = 1,\n",
    "        color = color,\n",
    "        title = title,\n",
    "        framestyle = :none)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Definition of the problem\n",
    "As a reminder, the GS model is defined from\n",
    "$\\begin{equation}\\begin{cases} \\frac{du}{dt} = D_u \\Delta u - uv^2 + f(1-u)  \\equiv F_u(u,v) \\\\ \\frac{dv}{dt} = D_v \\Delta v + uv^2 - (f+k)v  \\equiv G_v(u,v)\\end{cases} \\end{equation}$\n",
    "In this notebook we are going to try to solve the GS model formulated as follows:\n",
    "$\\begin{equation}\\begin{cases} \\frac{du}{dt} = D_u \\Delta u - uv^2 + NN_u \\\\ \\frac{dv}{dt} = D_v \\Delta v + uv^2 + NN_v \\end{cases} \\end{equation}$\n",
    "where $NN_u$ and $NN_v$ are closure terms that are a neural networks, and account for the parameters $f$ and $(f+k)$ respectively."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we define elements common to all cases: a 2D grid, initial conditions, forces $F_u$ and $G_v$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definition of the grid"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import CoupledNODE: Grid, grid_to_linear, linear_to_grid\n",
    "dx = dy = 1.0\n",
    "nx = ny = 64\n",
    "grid_GS = Grid(dim = 2, dx = dx, nx = nx, dy = dy, ny = ny)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definition of the initial condition as a random perturbation over a constant background to add variety."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import Random\n",
    "rng = Random.seed!(1234);\n",
    "function initial_condition(grid_u, grid_v, U₀, V₀, ε_u, ε_v; nsimulations = 1)\n",
    "    u_init = U₀ .+ ε_u .* Random.randn(grid_u.nx, grid_u.ny, nsimulations)\n",
    "    v_init = V₀ .+ ε_v .* Random.randn(grid_v.nx, grid_v.ny, nsimulations)\n",
    "    return u_init, v_init\n",
    "end\n",
    "U₀ = 0.5    # initial concentration of u\n",
    "V₀ = 0.25   # initial concentration of v\n",
    "ε_u = 0.05  # magnitude of the perturbation on u\n",
    "ε_v = 0.1   # magnitude of the perturbation on v\n",
    "u_initial, v_initial = initial_condition(\n",
    "    grid_GS, grid_GS, U₀, V₀, ε_u, ε_v, nsimulations = 20);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We define the initial condition as a flattened concatenated array"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "uv0 = vcat(reshape(u_initial, grid_GS.N, :), reshape(v_initial, grid_GS.N, :));"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "These are the GS parameters (also used in example 02.01) that we will try to learn"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "D_u = 0.16\n",
    "D_v = 0.08\n",
    "f = 0.055\n",
    "k = 0.062;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exact right hand sides (functions) of the GS model"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import CoupledNODE: Laplacian\n",
    "F_u(u, v) = D_u * Laplacian(u, grid_GS.dx, grid_GS.dy) .- u .* v .^ 2 .+ f .* (1.0 .- u)\n",
    "G_v(u, v) = D_v * Laplacian(v, grid_GS.dx, grid_GS.dy) .+ u .* v .^ 2 .- (f + k) .* v"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We're going to perform some burnput runs in order to get to an initial state common to all cases"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import Lux\n",
    "import CoupledNODE: create_f_CNODE"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definition of the CNODE that is not closed (i.e. no neural closure term)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "f_burnout = create_f_CNODE((F_u, G_v), (grid_GS, grid_GS); is_closed = false);\n",
    "θ_0, st_0 = Lux.setup(rng, f_burnout); # placeholder parameters (not meaningful)\n",
    "\n",
    "import DifferentialEquations: Tsit5\n",
    "solver_algo = Tsit5(); # defined for all cases\n",
    "import DiffEqFlux: NeuralODE\n",
    "trange_burn = (0.0, 1.0)\n",
    "dt, saveat = (1e-2, 1)\n",
    "burnout_CNODE = NeuralODE(f_burnout,\n",
    "    trange_burn,\n",
    "    solver_algo,\n",
    "    adaptive = false,\n",
    "    dt = dt,\n",
    "    saveat = saveat);\n",
    "burnout_CNODE_solution = Array(burnout_CNODE(uv0, θ_0, st_0)[1]);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will use the last state of the burnout as the initial condition for the next exploration"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "uv0 = burnout_CNODE_solution[:, :, end];"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We define de time span, dt and saveat cused to generate the solutions that we want to compare."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "trange = (0.0, 2000.0);\n",
    "dt, saveat = (1 / (4 * max(D_u, D_v)), 10);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the **exact solution**: target data that is going to be used to train the neural network."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "exact_sol_problem = NeuralODE(\n",
    "    f_burnout, trange, solver_algo, adaptive = false, dt = dt, saveat = saveat);\n",
    "exact_sol = Array(exact_sol_problem(uv0, θ_0, st_0)[1]);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "`41.340940 seconds (2.18 M allocations: 298.835 GiB, 31.85% gc time)`"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "u_exact_sol, v_exact_sol = reshape_ODESolution(exact_sol, grid_GS);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We create now the data used for training (input) with shape `(nux * nuy + nvx * nvy, nsimulations * timesteps)`"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "uv_data = reshape(exact_sol, size(exact_sol, 1), size(exact_sol, 2) * size(exact_sol, 3));"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "and the labels (forces because we will do apriori fitting)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "forces_target = Array(f_burnout(uv_data, θ_0, st_0)[1]);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the forces"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import Zygote\n",
    "function F_u_open(u, v)\n",
    "    Zygote.@ignore D_u * Laplacian(u, grid_GS.dx, grid_GS.dy) .- u .* v .^ 2\n",
    "end;\n",
    "function G_v_open(u, v)\n",
    "    Zygote.@ignore D_v * Laplacian(v, grid_GS.dx, grid_GS.dy) .+ u .* v .^ 2\n",
    "end;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the trainable part, we define an abstract Lux layer"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "struct GSLayer{F} <: Lux.AbstractExplicitLayer\n",
    "    init_weight::F\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "and its (outside) constructor"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function GSLayer(; init_weight = Lux.zeros32)\n",
    "    #function GSLayer(; init_weight = Lux.glorot_uniform)\n",
    "    return GSLayer(init_weight)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We also need to specify how to initialize its parameters and states.\n",
    "This custom layer does not have any hidden states (RNGs) that are modified."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function Lux.initialparameters(rng::Random.AbstractRNG, (; init_weight)::GSLayer)\n",
    "    (;\n",
    "        gs_weights = init_weight(rng, 3),)\n",
    "end\n",
    "Lux.initialstates(::Random.AbstractRNG, ::GSLayer) = (;)\n",
    "Lux.parameterlength((;)::GSLayer) = 3\n",
    "Lux.statelength(::GSLayer) = 0"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We define how to pass inputs through `GSlayer`, assuming the following:\n",
    "- Input size: `(N, N, 2, nsample)`, where the two channels are $u$ and $v$.\n",
    "- Output size: `(N, N, nsample)` where we assumed monochannel output, so we dropped the channel dimension."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is what each layer does. Notice that the layer does not modify the state."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function ((;)::GSLayer)(x, params, state)\n",
    "    (u, v) = x\n",
    "    out = params.gs_weights[1] .* u .+ params.gs_weights[2] .* v .+ params.gs_weights[3]\n",
    "    out, state\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We create the trainable models. In this case is just a GS layer, but the model can be as complex as needed."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "NN_u = GSLayer()\n",
    "NN_v = GSLayer()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## a. NeuralODE + CoupledNODE\n",
    "Create the CNODE with the Neural Network"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "f_CNODE = create_f_CNODE(\n",
    "    (F_u_open, G_v_open), (grid_GS, grid_GS), (NN_u, NN_v); is_closed = true);\n",
    "θ, st = Lux.setup(rng, f_CNODE);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "create loss"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import CoupledNODE: create_randloss_derivative\n",
    "neuralODE_loss = create_randloss_derivative(uv_data, forces_target, f_CNODE, st;\n",
    "    n_use = 64, λ = 0);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set up optimizer"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import ComponentArrays\n",
    "import OptimizationOptimisers: Optimization, OptimiserChain, Adam\n",
    "adtype = Optimization.AutoZygote();\n",
    "train_algo = OptimiserChain(Adam(1.0e-3));\n",
    "opt_f_neuralODE = Optimization.OptimizationFunction((x, p) -> neuralODE_loss(x), adtype);\n",
    "opt_prob_neuralODE = Optimization.OptimizationProblem(\n",
    "    opt_f_neuralODE, ComponentArrays.ComponentArray(θ););"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "training"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import CoupledNODE: callback\n",
    "result_opt_neuralode = Optimization.solve(opt_prob_neuralODE, train_algo;\n",
    "    callback = callback, maxiters = 1000);\n",
    "θ = result_opt_neuralode.u;\n",
    "opt_prob_neuralODE = Optimization.OptimizationProblem(\n",
    "    opt_f_neuralODE, ComponentArrays.ComponentArray(θ););"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "get solution"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "neuralODE_problem = NeuralODE(\n",
    "    f_CNODE, trange, solver_algo, adaptive = false, dt = dt, saveat = saveat);\n",
    "@time neuralODE_sol = Array(neuralODE_problem(uv0, θ, st)[1]);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "`45.172009 seconds (3.28 M allocations: 317.659 GiB, 14.78% gc time, 0.83% compilation time)`"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "u_neural_ODE, v_neural_ODE = reshape_ODESolution(neuralODE_sol, grid_GS);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### b. ODEProblem\n",
    "We first define a set of parameters for training in this setup and a right hand side that is a wrapper\n",
    "written in the way that is valid for defining an `ODEProblem`."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "θ_ODE, st_ODE = Lux.setup(rng, f_CNODE);\n",
    "function rhs_ode_problem(u, p, t)\n",
    "    f_CNODE(u, θ_ODE, st_ODE)[1]\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "define the optimization problem and train"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "opt_prob_ODE = Optimization.OptimizationProblem(\n",
    "    opt_f_neuralODE, ComponentArrays.ComponentArray(θ_ODE););\n",
    "result_opt_ode = Optimization.solve(\n",
    "    opt_prob_ODE, train_algo; callback = callback, maxiters = 1000);\n",
    "θ_ODE = result_opt_ode.u;\n",
    "opt_prob_ODE = Optimization.OptimizationProblem(\n",
    "    opt_f_neuralODE, ComponentArrays.ComponentArray(θ_ODE););"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "then create the problem and solve it:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using DifferentialEquations: ODEProblem, solve\n",
    "ODE_problem = ODEProblem(rhs_ode_problem, uv0, trange);\n",
    "@time ODE_sol = solve(ODE_problem, solver_algo, adaptive = false, dt = dt, saveat = saveat);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "`45.490858 seconds (3.09 M allocations: 317.156 GiB, 14.74% gc time, 0.75% compilation time)`"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "u_ODE, v_ODE = reshape_ODESolution(Array(ODE_sol), grid_GS);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### c. [SplitODE](https://docs.sciml.ai/DiffEqDocs/stable/types/split_ode_types/)\n",
    "`SplitODEProblem` considers a problem with two functions $f_1$ and $f_2$, and it has been used by Hugo Melchers in his Master thesis: [Neural closure models](https://github.com/HugoMelchers/neural-closure-models/blob/main/src/training/models/split_neural_odes.jl).\n",
    "We are going to redefine the forces split in two functions:\n",
    "$\\begin{equation} \\frac{du}{dt} f_1(u,p,t) + f_2(u,p,t) \\end{equation}$\n",
    "We are going to abstract:\n",
    "- $f_1$: known part of the equation.\n",
    "- $f_2$: Closure term, neural network.\n",
    "We define the forces out-of-place because for the loss is easier if we can get the prediction (force)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function f1(u, p, t)\n",
    "    u_gs = @view u[1, :, :, :]\n",
    "    v_gs = @view u[2, :, :, :]\n",
    "    du_gs = F_u_open(u_gs, v_gs)\n",
    "    dv_gs = G_v_open(u_gs, v_gs)\n",
    "    return permutedims(cat(du_gs, dv_gs, dims = 4), [4, 1, 2, 3])\n",
    "end\n",
    "\n",
    "function f2(u, p, t)\n",
    "    u_gs = @view u[1, :, :, :]\n",
    "    v_gs = @view u[2, :, :, :]\n",
    "    du_gs = NN_u((u_gs, v_gs), p.θ_u, st_u)[1]\n",
    "    dv_gs = NN_v((u_gs, v_gs), p.θ_v, st_v)[1]\n",
    "    return permutedims(cat(du_gs, dv_gs, dims = 4), [4, 1, 2, 3])\n",
    "end\n",
    "\n",
    "function rhs_split(u, p, t)\n",
    "    f1(u, p, t) + f2(u, p, t)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Parameters of the neural networks"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "θ_u, st_u = Lux.setup(rng, NN_u);\n",
    "θ_v, st_v = Lux.setup(rng, NN_v);\n",
    "p_split = ComponentArrays.ComponentArray(; θ_u = θ_u, θ_v = θ_v);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "we are going to reshape the inputs and labels to make it consistent with this new formulation"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "u0 = permutedims(cat(u_initial, v_initial, dims = 4), [4, 1, 2, 3]); # 2x64x64x20 n_vars x nx x ny x n_samples\n",
    "uv_data_grid = permutedims(cat(u_exact_sol, v_exact_sol, dims = 5), [5, 1, 2, 3, 4]);\n",
    "uv_data_grid = reshape(uv_data_grid, size(uv_data_grid)[1:3]..., :);\n",
    "force_u, force_v = reshape_ODESolution(forces_target, grid_GS);\n",
    "forces_target_grid = permutedims(\n",
    "    cat(force_u[:, :, :, 1], force_v[:, :, :, 1], dims = 4), [4, 1, 2, 3]);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "NOTE: we cannot use `create_randloss_derivative` because when getting a prediction form the model we fetch the data via `Array(f(u)[1])` but with all ODESolutions we do it as `Array(f(u))`. This is because NeuralODE returns a tuple while other solvers return ODESolutions directly. See [this comment of C. Rackauckas](https://discourse.julialang.org/t/neural-ode-in-diffeqflux-that-is-not-a-time-series/22395/7): \"Neural ODE returns the array and not the ODESolution because of the constraints on it’s AD\""
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function split_loss(θ)\n",
    "    pred = rhs_split(uv_data_grid, θ, 0)\n",
    "    return sum(abs2, pred .- forces_target_grid) / sum(abs2, forces_target_grid), nothing\n",
    "end\n",
    "\n",
    "opt_f_split = Optimization.OptimizationFunction((x, p) -> split_loss(x), adtype);\n",
    "opt_prob_split = Optimization.OptimizationProblem(opt_f_split, p_split);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "training"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import CoupledNODE: callback\n",
    "result_opt_split = Optimization.solve(\n",
    "    opt_prob_split, train_algo; callback = callback, maxiters = 200);\n",
    "p_split = result_opt_split.u;\n",
    "opt_prob_split = Optimization.OptimizationProblem(opt_f_split, p_split);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Note:_ This model takes very long to train because we are using all the data in the loss, not randomly selected samples (1st hypothesis)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using DifferentialEquations: SplitODEProblem, solve\n",
    "split_problem = SplitODEProblem(f1, f2, u0, trange);\n",
    "@time split_sol = solve(split_problem, solver_algo, p = p_split, adaptive = false,\n",
    "    dt = dt, saveat = saveat, progress = true);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "`57.961440 seconds (5.72 M allocations: 336.088 GiB, 12.60% gc time, 1.39% compilation time)`"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "u_split = Array(split_sol)[1, :, :, :, :];\n",
    "v_split = Array(split_sol)[2, :, :, :, :];"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### d. ODEProblem following [Missing Physics showcase](https://docs.sciml.ai/Overview/stable/showcase/missing_physics/)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "#Multilayer FeedForward\n",
    "rbf(x) = exp.(-(x .^ 2))\n",
    "const U = Lux.Chain(Lux.Dense(2, 5, rbf), Lux.Dense(5, 5, rbf), Lux.Dense(5, 5, rbf),\n",
    "    Lux.Dense(5, 2))\n",
    "\n",
    "#U(u0, p_mp, _st)[1]\n",
    "#Get the initial parameters and state variables of the model\n",
    "p_mp, st_mp = Lux.setup(rng, U)\n",
    "const _st = st_mp"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "UDE: universal differential equation : `u' = known(u) + NN(u)` in our case `F_u_open` and `G_v_open` contain part of the known physics.\n",
    "The NNs should approximate the rest."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function ude!(du, u, p, t)\n",
    "    u_gs = @view u[1, :, :, :]\n",
    "    v_gs = @view u[2, :, :, :]\n",
    "    du_gs = @view du[1, :, :, :]\n",
    "    dv_gs = @view du[2, :, :, :]\n",
    "    u_nn = U(u, p, _st)[1]\n",
    "    du_gs .= F_u_open(u_gs, v_gs) + u_nn[1, :, :, :]\n",
    "    dv_gs .= G_v_open(u_gs, v_gs) + u_nn[2, :, :, :]\n",
    "end\n",
    "\n",
    "prob_nn = ODEProblem(ude!, u0, trange, p_mp)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Trainin loop"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using SciMLSensitivity: QuadratureAdjoint, ReverseDiffVJP\n",
    "function predict(θ, X = u0, T = trange)\n",
    "    _prob = remake(prob_nn, u0 = X, tspan = (T[1], T[end]), p = θ)\n",
    "    Array(solve(_prob, solver_algo, saveat = saveat, dt = dt,\n",
    "        sensealg = QuadratureAdjoint(autojacvec = ReverseDiffVJP(true))))\n",
    "end\n",
    "\n",
    "function loss_mp(θ)\n",
    "    X̂ = predict(θ)\n",
    "    mean(abs2, forces_target_grid .- X̂)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "I think there is a problem here, X̂ is the solution (u,v) not the forces."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "training"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "optf = Optimization.OptimizationFunction((x, p) -> loss_mp(x), adtype)\n",
    "optprob = Optimization.OptimizationProblem(\n",
    "    optf, ComponentArrays.ComponentVector{Float64}(p_mp))\n",
    "res1 = Optimization.solve(optprob, train_algo, callback = callback, maxiters = 100)\n",
    "\n",
    "p_trained = res1.u\n",
    "sol_mp = predict(p_trained, u0, trange)\n",
    "u_mp = @view sol_mp[1, :, :, :]\n",
    "v_mp = @view sol_mp[2, :, :, :]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### e. NeuralPDE.jl [NNODE](https://docs.sciml.ai/NeuralPDE/stable/manual/ode/#ODE-Specialized-Physics-Informed-Neural-Network-(PINN)-Solver)\n",
    "[NNODE](https://docs.sciml.ai/NeuralPDE/stable/tutorials/ode/) is a specific implementation for PINNs such that for an ODE problem:\n",
    "\\begin{equation} \\frac{du}{dt}=f(u,p,t) \\end{equation}\n",
    "They consider that the solution of the ODE $u \\approx NN$ and thus:\n",
    "\\begin{equation} NN'= f(NN, p, t) \\end{equation}\n",
    "Let's follow [the tutorial on parameter estimation with PINNs](https://docs.sciml.ai/NeuralPDE/stable/tutorials/ode_parameter_estimation/)\n",
    "to find a NN that the parameters $f$ and $k$ to fit the GS Model.\n",
    "We define the force out-of-place because NNODE only supports this type"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function GS(u, p, t)\n",
    "    u_gs = @view u[1, :, :, :]\n",
    "    v_gs = @view u[2, :, :, :]\n",
    "    f, k = p #parameters\n",
    "    du_gs = D_u * Laplacian(u_gs, grid_GS.dx, grid_GS.dy) .- u_gs .* v_gs .^ 2 .+\n",
    "            f .* (1.0 .- u_gs)\n",
    "    dv_gs = D_v * Laplacian(v_gs, grid_GS.dx, grid_GS.dy) .+ u_gs .* v_gs .^ 2 .-\n",
    "            (f + k) .* v_gs\n",
    "    return permutedims(cat(du_gs, dv_gs, dims = 4), [4, 1, 2, 3])\n",
    "end\n",
    "\n",
    "using DifferentialEquations: remake\n",
    "u0 = permutedims(cat(u_initial, v_initial, dims = 4), [4, 1, 2, 3]); # 2x64x64x20 n_vars x nx x ny x n_samples\n",
    "prob = ODEProblem(GS, u0, trange, [1.0, 1.0]);\n",
    "true_p = [f, k]\n",
    "prob_data = remake(prob, p = true_p);\n",
    "sol_data = solve(prob_data, solver_algo, saveat = saveat)\n",
    "#t_ = sol_data.t; # timesteps\n",
    "u_ = Array(sol_data)\n",
    "u_ = reshape(u_, size(u_)[1:3]..., :) # merging last two dimensions: n_simualtions and time\n",
    "labels_ = GS(u_, true_p, true_p)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We build an MLP with 3 layers with `n` neurons.\n",
    "- input: 1D time (?)\n",
    "- output: 2D du, dt (?)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "n = 15\n",
    "NN_PDE = Lux.Chain(\n",
    "    Lux.Dense(1, n, Lux.σ),\n",
    "    Lux.Dense(n, n, Lux.σ),\n",
    "    Lux.Dense(n, n, Lux.σ),\n",
    "    Lux.Dense(n, 2)\n",
    ")\n",
    "ps, st = Lux.setup(rng, NN_PDE) |> Lux.f64\n",
    "function additional_loss(phi, θ)\n",
    "    println(size(phi(u_, θ)))\n",
    "    return sum(abs2, phi(u_, θ) .- labels_) / sum(abs2, labels_)\n",
    "end\n",
    "\n",
    "using NeuralPDE: NNODE, WeightedIntervalTraining\n",
    "strategy_1 = WeightedIntervalTraining([0.7, 0.2, 0.1], 65) # last argument is number of intervals I think it has to match loss dimensions."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "NOTE: tried GridTraining because I saw it in the docs but then found that [is never a good idea to use it](https://github.com/SciML/NeuralPDE.jl/issues/551)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "alg_NNODE = NNODE(NN_PDE, train_algo, ps; strategy = strategy_1,\n",
    "    param_estim = true, additional_loss = additional_loss, dt = dt)\n",
    "sol = solve(prob, alg_NNODE, verbose = true, abstol = 1e-8,\n",
    "    maxiters = 5000, dt = dt, saveat = saveat)\n",
    "#TODO: still not working probably the strategy is not well defined but with the defaults is also a problem."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### f. NeuralPDE.jl and ModelingToolkit.jl"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using NeuralPDE, Flux, ModelingToolkit, DiffEqFlux"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the parameters for the problem"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@parameters t x y\n",
    "@variables u(..) v(..)\n",
    "Dxx = Differential(x)^2\n",
    "Dyy = Differential(y)^2"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the Gray-Scott equations"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "eqs = [\n",
    "    D(u(t, x, y)) ~ Dxx(u(t, x, y)) + Dyy(u(t, x, y)) - u(t, x, y) +\n",
    "                    u(t, x, y)^2 * v(t, x, y),\n",
    "    D(v(t, x, y)) ~ Dxx(v(t, x, y)) + Dyy(v(t, x, y)) - u(t, x, y)^2 * v(t, x, y)]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the domains and boundary conditions"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "domains = [t ∈ IntervalDomain(trange[1], trange[end]),\n",
    "    x ∈ IntervalDomain(0.0, nx),\n",
    "    y ∈ IntervalDomain(0.0, ny)]\n",
    "bcs = [u(0, x, y) ~ cos(pi * x) * cos(pi * y),\n",
    "    v(0, x, y) ~ sin(pi * x) * sin(pi * y),\n",
    "    u(t, 0, y) ~ u(t, 1, y),\n",
    "    u(t, x, 0) ~ u(t, x, 1),\n",
    "    v(t, 0, y) ~ v(t, 1, y),\n",
    "    v(t, x, 0) ~ v(t, x, 1)]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the neural networks and the symbolic neural pde"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "chain = Lux.Chain(Lux.Dense(3, 16, Flux.σ), Lux.Dense(16, 16, Flux.σ), Lux.Dense(16, 2))\n",
    "nnpde = PhysicsInformedNN(chain, GridTraining(dt), init_params = Flux.glorot_normal)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the discretization"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "discretization = NeuralPDE.discretize(nnpde, eqs, bcs, domains, dx = [0.1, 0.1, 0.1])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the optimization problem and solve it"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "prob = GalacticOptim.OptimizationProblem(\n",
    "    discretization, u0 = [1.0, 1.0], p = nothing, lb = [0.0, 0.0], ub = [1.0, 1.0])\n",
    "result = GalacticOptim.solve(prob, ADAM(0.1); cb = cb, maxiters = 4000)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison\n",
    "we check if there are any differences between the solutions"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "any(u_ODE - u_neural_ODE .!= 0.0)\n",
    "any(v_ODE - v_neural_ODE .!= 0.0)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see that there are differences between the solutions that can be due to the training."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plots"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Plots, Plots.PlotMeasures\n",
    "anim = Animation()\n",
    "fig = plot(layout = (3, 3), size = (1200, 400))\n",
    "@gif for i in 1:1:size(u_neural_ODE, 4)\n",
    "    p1 = GS_heatmap(u_exact_sol[:, :, 1, i], title = \"u\")\n",
    "    p2 = GS_heatmap(v_exact_sol[:, :, 1, i], title = \"v\", color = :blues)\n",
    "    p3 = GS_heatmap(u_neural_ODE[:, :, 1, i], title = \"u\")\n",
    "    p4 = GS_heatmap(v_neural_ODE[:, :, 1, i], title = \"v\", color = :blues)\n",
    "    p5 = GS_heatmap(u_split[:, :, 1, i])\n",
    "    p6 = GS_heatmap(v_split[:, :, 1, i], color = :blues)\n",
    "\n",
    "    #p5 = GS_heatmap(u_ODE[:, :, 1, i]-u_neural_ODE[:, :, 1, i], color = :greens)\n",
    "    #p6 = GS_heatmap(v_ODE[:, :, 1, i]-v_ODE[:, :, 1, i], color = :greens)\n",
    "\n",
    "    #Create titles as separate plots\n",
    "    t1 = plot(title = \"Exact\", framestyle = :none)\n",
    "    t2 = plot(title = \"NeuralODE\", framestyle = :none)\n",
    "    t3 = plot(title = \"SplitODE\", framestyle = :none)\n",
    "    #t4 = plot(title = \"Difference\", framestyle = :none)\n",
    "\n",
    "    fig = plot(t1, p1, p2, t2, p3, p4, t3, p5, p6,\n",
    "        layout = (3, 3),\n",
    "        margin = 0mm)\n",
    "    frame(anim, fig)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  },
  "kernelspec": {
   "name": "julia-1.10",
   "display_name": "Julia 1.10.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
