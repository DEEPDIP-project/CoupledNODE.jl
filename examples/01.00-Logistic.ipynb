{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic equation and NODE\n",
    "Let's study a phenomenon that can be described with the following ODE $$\\dfrac{dP}{dt} = rP\\left(1-\\dfrac{P}{K}\\right),$$ which is called the logistic equation. Given $P(t=0)=P_0$ we can solve this problem analytically to get $P(t) = \\frac{K}{1+\\left(K-P_0\\right)/P_0 \\cdot e^{-rt}}$. Let's plot the solution for $r=K=2, P_0=0.01$:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "r = 2\n",
    "K = 1\n",
    "P0 = 0.01\n",
    "function P(t)\n",
    "    return K / (1 + (K - P0) * exp(-r * t) / P0)\n",
    "end\n",
    "t = range(start = 0, stop = 6, step = 0.01)\n",
    "Pt = P.(t)\n",
    "using Plots\n",
    "plot(t, Pt, label = \"P(t)\", xlabel = \"t\", ylabel = \"P(t)\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's say that we want to use the logistic equation to model an experiment like the activation energy of a neuron. We run the experiment and we observe the following:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import DifferentialEquations: ODEProblem, solve, Tsit5\n",
    "function observation()\n",
    "    f_o(u, p, t) = u .* (0.0 .- 0.8 .* log.(u))\n",
    "    trange = (0.0, 6.0)\n",
    "    prob = ODEProblem(f_o, 0.01, trange, dt = 0.01, saveat = 0.01)\n",
    "    sol = solve(prob, Tsit5())\n",
    "    return sol.u\n",
    "end\n",
    "u_experiment = observation()\n",
    "using Plots\n",
    "plot(t, Pt, label = \"Best P(t) fit\")\n",
    "plot!(t, u_experiment[:], label = \"Observation(t)\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This means that our experimental system, despite its similarity, it is not described by a logistic ODE.\n",
    "How can we then model our experiment as an ODE?\n",
    "\n",
    "There are many simpler alternatives for this example (e.g. Mode Decomposition, SINDY or Bayesian methods), but let's use this exercise to introduce a NODE:\n",
    "$\\begin{equation}\\dfrac{du}{dt} = \\underbrace{ru\\left(1-\\dfrac{u}{K}\\right)}_{f(u)} + NN(u|\\theta).\\end{equation}$\n",
    "In this NODE we are looking for a solution $u(t)$ that reproduces our observation.\n",
    "We will be using [SciML](https://sciml.ai/) package [DiffEqFlux.jl](https://github.com/SciML/DiffEqFlux.jl) and scpecifically [NeuralODE](https://docs.sciml.ai/DiffEqFlux/stable/examples/neural_ode/) for defining and solving the problem.\n",
    "## Solve the NODE\n",
    "We solve this 1D NODE using introducing the functionalities of this repository:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* We create the NN using `Lux`. In this example we do not discuss the structure of the NN, but we leave it as a black box that can be designed by the user. We will show later how to take inspiration from the physics of the problem to design optimal NN."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import Lux\n",
    "NN = Lux.Chain(Lux.SkipConnection(Lux.Dense(1, 3),\n",
    "    (out, u) -> u * out[1] .+ u .* u .* out[2] .+ u .* log.(abs.(u)) .* out[3]));"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "* We define the force $f(u)$ compatibly with SciML."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "f_u(u) = @. r * u * (1.0 - u / K);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "* We create the right hand side of the NODE, by combining the NN with f_u"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import CoupledNODE: create_f_NODE\n",
    "f_NODE = create_f_NODE(NN, f_u; is_closed = true);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "and get the parametrs that you want to train"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import Random\n",
    "rng = Random.seed!(1234)\n",
    "θ, st = Lux.setup(rng, f_NODE);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "* We define the NODE"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import DiffEqFlux: NeuralODE\n",
    "trange = (0.0, 6.0)\n",
    "u0 = [0.01]\n",
    "full_NODE = NeuralODE(f_NODE, trange, Tsit5(), adaptive = false, dt = 0.001, saveat = 0.2);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "* We solve the NODE using the zero-initialized parameters\n",
    "*Note:* `full_NODE` is a `NeuralODE` function that returns a `DiffEqBase.ODESolution` object. This object contains the solution of the ODE, but it also contains additional information like the time points at which the solution was evaluated and the parameters of the ODE. We can access the solution using `[1]`, and we convert it to an `Array` to be able to use it for further calculations and plot."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "untrained_NODE_solution = Array(full_NODE(u0, θ, st)[1]);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare the model\n",
    "First, we define this auxiliary NODE that will be used for training"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dt = 0.01 # it has to be as fine as the data\n",
    "nunroll = 60\n",
    "t_train_range = (0.0, dt * (nunroll + 1)) # it has to be as long as unroll\n",
    "training_NODE = NeuralODE(f_NODE,\n",
    "    t_train_range,\n",
    "    Tsit5(),\n",
    "    adaptive = false,\n",
    "    dt = dt,\n",
    "    saveat = dt);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seconf, we need to design the **loss function**. For this example, we use *multishooting a posteriori* fitting [(MulDtO)](https://docs.sciml.ai/DiffEqFlux/dev/examples/multiple_shooting/). Using `Zygote` we compare `nintervals` of length `nunroll` to get the gradient. Notice that this method is differentiating through the solution of the NODE!"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import CoupledNODE: create_randloss_MulDtO_1\n",
    "nintervals = 10\n",
    "myloss = create_randloss_MulDtO_1(\n",
    "    u_experiment, training_NODE, st, nunroll = nunroll, nintervals = nintervals);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "To initialize the training, we need some objects to monitor the procedure, and we trigger the first compilation."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "lhist = [];"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize and trigger the compilation of the model"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import ComponentArrays\n",
    "pinit = ComponentArrays.ComponentArray(θ);\n",
    "myloss(pinit); # trigger compilation"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Select the autodifferentiation type"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import OptimizationOptimisers: Optimization\n",
    "adtype = Optimization.AutoZygote();"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We transform the NeuralODE into an optimization problem"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "optf = Optimization.OptimizationFunction((x, p) -> myloss(x), adtype);\n",
    "optprob = Optimization.OptimizationProblem(optf, pinit);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Select the training algorithm:\n",
    "We choose Adam with learning rate 0.1, with gradient clipping"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import OptimizationOptimisers: OptimiserChain, Adam, ClipGrad\n",
    "ClipAdam = OptimiserChain(Adam(1.0e-1), ClipGrad(1));"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train de NODE\n",
    "We are ready to train the NODE.\n",
    "Notice that the block can be repeated to continue training"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import CoupledNODE: callback\n",
    "result_neuralode = Optimization.solve(optprob,\n",
    "    ClipAdam;\n",
    "    callback = callback,\n",
    "    maxiters = 100)\n",
    "pinit = result_neuralode.u;\n",
    "optprob = Optimization.OptimizationProblem(optf, pinit);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyse the results\n",
    "Visualize the obtained results"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot()\n",
    "plot(t, Pt, label = \"Best P(t) fit\")\n",
    "plot!(t, u_experiment[:], label = \"Observation(t)\")\n",
    "scatter!(range(start = 0, stop = 6, step = 0.2),\n",
    "    untrained_NODE_solution[:],\n",
    "    label = \"untrained NODE\",\n",
    "    marker = :circle)\n",
    "scatter!(range(start = 0, stop = 6, step = 0.2),\n",
    "    Array(full_NODE([u_experiment[1]], result_neuralode.u, st)[1])[:],\n",
    "    label = \"Trained NODE\",\n",
    "    marker = :circle)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  },
  "kernelspec": {
   "name": "julia-1.10",
   "display_name": "Julia 1.10.2",
   "language": "julia"
  }
 },
 "nbformat": 4
}
