{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Learning the Gray-Scott model: a posteriori fitting\n",
    "In this example, we will learn how to approximate a closure to the Gray-Scott model with a Neural Network trained via a posteriori fitting, using a [multishooting](https://docs.sciml.ai/DiffEqFlux/dev/examples/multiple_shooting/) approach."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a reminder, the GS model is defined from\n",
    "\\begin{equation}\\begin{cases} \\frac{du}{dt} = D_u \\Delta u - uv^2 + f(1-u)  \\equiv F_u(u,v) \\\\ \\frac{dv}{dt} = D_v \\Delta v + uv^2 - (f+k)v  \\equiv G_v(u,v)\\end{cases} \\end{equation}\n",
    "where $u(x,y,t):\\mathbb{R}^2\\times \\mathbb{R}\\rightarrow \\mathbb{R}$ is the concentration of species 1, while $v(x,y,t)$ is the concentration of species two. This model reproduce the effect of the two species diffusing in their environment, and reacting together.\n",
    "This effect is captured by the ratios between $D_u$ and $D_v$ (the diffusion coefficients) and $f$ and $k$ (the reaction rates)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As in the repvious example, we will first (I) use the exact GS model to gather some data and then in the second part (II) we will train a neural network to approximate the GS model using a posteriori fitting."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## I. Solving GS to collect data\n",
    "Definition of the grid"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import CoupledNODE: Grid\n",
    "dux = duy = dvx = dvy = 1.0\n",
    "nux = nuy = nvx = nvy = 64\n",
    "grid_GS_u = Grid(dim = 2, dx = dux, nx = nux, dy = duy, ny = nuy);\n",
    "grid_GS_v = Grid(dim = 2, dx = dvx, nx = nvx, dy = dvy, ny = nvy);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the initial condition as a random perturbation over a constant background to add variety. Notice that in this case we are generating only 2 samples (i.e. `nsimulations=2`). This is because for the *a posteriori fitting* we are using a fine sampling."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import Random\n",
    "function initial_condition(grid_u, grid_v, U₀, V₀, ε_u, ε_v; nsimulations = 1)\n",
    "    u_init = U₀ .+ ε_u .* Random.randn(grid_u.nx, grid_u.ny, nsimulations)\n",
    "    v_init = V₀ .+ ε_v .* Random.randn(grid_v.nx, grid_v.ny, nsimulations)\n",
    "    return u_init, v_init\n",
    "end\n",
    "U₀ = 0.5    # initial concentration of u\n",
    "V₀ = 0.25   # initial concentration of v\n",
    "ε_u = 0.05  # magnitude of the perturbation on u\n",
    "ε_v = 0.1   # magnitude of the perturbation on v\n",
    "u_initial, v_initial = initial_condition(\n",
    "    grid_GS_u, grid_GS_v, U₀, V₀, ε_u, ε_v, nsimulations = 2);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "$u$ and $v$ are concatenated in a flattended array"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "uv0 = vcat(reshape(u_initial, grid_GS_u.N, :), reshape(v_initial, grid_GS_v.N, :));"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "These are the GS parameters (also used in examples 02.01 and 02.02) that we will try to learn."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "D_u = 0.16\n",
    "D_v = 0.08\n",
    "f = 0.055\n",
    "k = 0.062;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exact right hand sides of the GS model:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import CoupledNODE: Laplacian\n",
    "F_u(u, v) = D_u * Laplacian(u, grid_GS_u.dx, grid_GS_u.dy) .- u .* v .^ 2 .+ f .* (1.0 .- u)\n",
    "G_v(u, v) = D_v * Laplacian(v, grid_GS_v.dx, grid_GS_v.dy) .+ u .* v .^ 2 .- (f + k) .* v"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "CNODE definition"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import Lux\n",
    "import CoupledNODE: create_f_CNODE\n",
    "f_CNODE = create_f_CNODE((F_u, G_v), (grid_GS_u, grid_GS_v); is_closed = false);\n",
    "rng = Random.seed!(1234);\n",
    "θ_0, st_0 = Lux.setup(rng, f_CNODE);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Burnout run**"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import DifferentialEquations: Tsit5\n",
    "import DiffEqFlux: NeuralODE\n",
    "trange_burn = (0.0, 1.0)\n",
    "dt, saveat = (1e-2, 1)\n",
    "burnout_CNODE = NeuralODE(f_CNODE,\n",
    "    trange_burn,\n",
    "    Tsit5(),\n",
    "    adaptive = false,\n",
    "    dt = dt,\n",
    "    saveat = saveat);\n",
    "burnout_CNODE_solution = Array(burnout_CNODE(uv0, θ_0, st_0)[1]);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Second burnout with a larger timestep"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "trange_burn = (0.0, 800.0)\n",
    "dt, saveat = (1 / (4 * max(D_u, D_v)), 100)\n",
    "burnout_CNODE = NeuralODE(f_CNODE,\n",
    "    trange_burn,\n",
    "    Tsit5(),\n",
    "    adaptive = false,\n",
    "    dt = dt,\n",
    "    saveat = saveat);\n",
    "burnout_CNODE_solution = Array(burnout_CNODE(burnout_CNODE_solution[:, :, end], θ_0, st_0)[1]);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data collection run"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "uv0 = burnout_CNODE_solution[:, :, end]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the a-posteriori fitting, we use a fine sampling for two reasons:\n",
    "1. use a handlable amount of data points\n",
    "2. prevent instabilities while training\n",
    "However, this means that the simulation cannot be long."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dt, saveat = (1 / (4 * max(D_u, D_v)), 0.001)\n",
    "trange = (0.0, 50.0)\n",
    "GS_CNODE = NeuralODE(f_CNODE, trange, Tsit5(), adaptive = false, dt = dt, saveat = saveat);\n",
    "GS_sim = Array(GS_CNODE(uv0, θ_0, st_0)[1])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## II. Training a CNODE to learn the GS model via a posteriori training\n",
    "To learn the GS model, we will use the following CNODE\n",
    "$\\begin{equation}\\begin{cases} \\frac{du}{dt} = D_u \\Delta u + \\theta_{u,1} uv^2 +\\theta_{u,2} v^2u + \\theta_{u,3} u +\\theta_{u,4} v +\\theta_{u,5}  \\\\ \\frac{dv}{dt} = D_v \\Delta v + \\theta_{v,1} uv^2 + \\theta_{v,2} v^2u +\\theta_{v,3} u +\\theta_{v,4} v +\\theta_{v,5} \\end{cases} \\end{equation}$\n",
    "In this example the deterministic function contains the diffusion and the coupling terms, while the model has to learn the source and death terms.\n",
    "Then the deterministic functions of the two coupled equations are"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import Zygote\n",
    "function F_u_open(u, v)\n",
    "    Zygote.@ignore D_u * Laplacian(u, grid_GS_u.dx, grid_GS_u.dy) .- u .* v .^ 2\n",
    "end\n",
    "function G_v_open(u, v)\n",
    "    Zygote.@ignore D_v * Laplacian(v, grid_GS_v.dx, grid_GS_v.dy) .+ u .* v .^ 2\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We tell Zygote to ignore this tree branch for the gradient propagation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definition of Neural functions\n",
    "In this case we define different architectures for $u$: $NN_u$ and $v$: $NN_v$, to make the training easier."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "struct GSLayer_u{F} <: Lux.AbstractExplicitLayer\n",
    "    init_weight::F\n",
    "end\n",
    "function GSLayer_u(; init_weight = Lux.zeros32)\n",
    "    return GSLayer_u(init_weight)\n",
    "end\n",
    "struct GSLayer_v{F} <: Lux.AbstractExplicitLayer\n",
    "    init_weight::F\n",
    "end\n",
    "function GSLayer_v(; init_weight = Lux.zeros32)\n",
    "    return GSLayer_v(init_weight)\n",
    "end\n",
    "\n",
    "function Lux.initialparameters(rng::Random.AbstractRNG, (; init_weight)::GSLayer_u)\n",
    "    (;\n",
    "        gs_weights = init_weight(rng, 2),)\n",
    "end\n",
    "function Lux.initialparameters(rng::Random.AbstractRNG, (; init_weight)::GSLayer_v)\n",
    "    (;\n",
    "        gs_weights = init_weight(rng, 1),)\n",
    "end\n",
    "Lux.initialstates(::Random.AbstractRNG, ::GSLayer_u) = (;)\n",
    "Lux.initialstates(::Random.AbstractRNG, ::GSLayer_v) = (;)\n",
    "Lux.parameterlength((;)::GSLayer_u) = 2\n",
    "Lux.parameterlength((;)::GSLayer_v) = 1\n",
    "Lux.statelength(::GSLayer_u) = 0\n",
    "Lux.statelength(::GSLayer_v) = 0\n",
    "function ((;)::GSLayer_u)(x, params, state)\n",
    "    (u, _) = x\n",
    "    out = params.gs_weights[1] .* u .+ params.gs_weights[2]\n",
    "    out, state\n",
    "end\n",
    "function ((;)::GSLayer_v)(x, params, state)\n",
    "    (_, v) = x\n",
    "    out = params.gs_weights[1] .* v\n",
    "    out, state\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The trainable parts are thus:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "NN_u = GSLayer_u()\n",
    "NN_v = GSLayer_v()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Close the CNODE with the Neural Network"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "f_closed_CNODE = create_f_CNODE(\n",
    "    (F_u_open, G_v_open), (grid_GS_u, grid_GS_v), (NN_u, NN_v); is_closed = true)\n",
    "θ, st = Lux.setup(rng, f_closed_CNODE);\n",
    "import ComponentArrays\n",
    "θ = ComponentArrays.ComponentArray(θ)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Design the loss function - a posteriori fitting\n",
    "In *a posteriori* fitting, we rely on a differentiable solver to propagate the gradient through the solution of the NODE. In this case, we use the *multishooting a posteriori* fitting [(MulDtO)](https://docs.sciml.ai/DiffEqFlux/dev/examples/multiple_shooting/), where we use `Zygote` to compare `nintervals` of length `nunroll` to get the gradient. Notice that this method is differentiating through the solution of the NODE!"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "nunroll = 10\n",
    "nintervals = 5\n",
    "noverlaps = 1\n",
    "nsamples = 1;"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we want to control the time step and the total length of the solutions that we have to compute at each iteration, we  define an auxiliary NODE that will be used for training.\n",
    "In particular, we can use smaller time steps for the training, but have to sample at the same rate as the data.\n",
    "Also, it is important to solve for only the time interval thas is needed at each training step (corresponding to `nunroll` steps)\n",
    "*Note:* The GS model is stiff, so we need to use a small time step to solve it. In previous versions we had two different CNODEs, the second one would be used in case the solver would be unstable. In this version, we stick to a smaller time step that those used in the previous examples to avoid instabilities."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "dt_train = 0.001;\n",
    "saveat_train = saveat\n",
    "t_train_range = (0.0, saveat_train * nunroll)\n",
    "training_CNODE = NeuralODE(f_closed_CNODE,\n",
    "    t_train_range,\n",
    "    Tsit5(),\n",
    "    adaptive = false,\n",
    "    dt = dt_train,\n",
    "    saveat = saveat_train);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the loss"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import CoupledNODE: create_randloss_MulDtO\n",
    "myloss = create_randloss_MulDtO(GS_sim,\n",
    "    training_CNODE,\n",
    "    st,\n",
    "    nunroll = nunroll,\n",
    "    noverlaps = noverlaps,\n",
    "    nintervals = nintervals,\n",
    "    nsamples = nsamples,\n",
    "    λ_c = 1e2,\n",
    "    λ_l1 = 1e-1);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize and trigger the compilation of the model"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pinit = ComponentArrays.ComponentArray(θ)\n",
    "myloss(pinit)  # trigger compilation"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "⚠️ Check that the loss does not get type warnings, otherwise it will be slower"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Autodifferentiation type"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import OptimizationOptimisers: Optimization\n",
    "using Statistics\n",
    "adtype = Optimization.AutoZygote();"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We transform the NeuralODE into an optimization problem"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "optf = Optimization.OptimizationFunction((x, p) -> myloss(x), adtype);\n",
    "optprob = Optimization.OptimizationProblem(optf, pinit);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training algorithm\n",
    "In this example we use Adam optimizer. As we have seen other optimization methods can be used."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import OptimizationOptimisers: OptimiserChain, Adam\n",
    "algo = OptimiserChain(Adam(1.0e-1));\n",
    "\n",
    "#using OptimizationCMAEvolutionStrategy, Statistics\n",
    "#algo = CMAEvolutionStrategyOpt();"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the CNODEs"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import CoupledNODE: callback\n",
    "result_neuralode = Optimization.solve(optprob,\n",
    "    algo;\n",
    "    callback = callback,\n",
    "    maxiters = 100);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We may get `**Warning:** Instability detected. Aborting` for the first time steps of the training. This is due to the stiff nature of the GS model as explained earlier. The training will continue after the first few steps."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pinit = result_neuralode.u;\n",
    "θ = pinit\n",
    "optprob = Optimization.OptimizationProblem(optf, pinit);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## III. Analyse the results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparison: learned weights vs (expected) values of the parameters"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Plots, Plots.PlotMeasures\n",
    "correct_w_u = [-f, f]\n",
    "correct_w_v = [-(f + k)]\n",
    "gs_w_u = θ.layer_2.layer_1.gs_weights\n",
    "gs_w_v = θ.layer_2.layer_2.gs_weights\n",
    "p1 = scatter(gs_w_u,\n",
    "    label = \"learned\",\n",
    "    title = \"Comparison NN_u coefficients\",\n",
    "    xlabel = \"Index\",\n",
    "    ylabel = \"Value\")\n",
    "scatter!(p1, correct_w_u, label = \"correct\")\n",
    "p2 = scatter(gs_w_v,\n",
    "    label = \"learned\",\n",
    "    title = \"Comparison NN_v coefficients\",\n",
    "    xlabel = \"Index\",\n",
    "    ylabel = \"Value\")\n",
    "scatter!(p2, correct_w_v, label = \"correct\")\n",
    "p = plot(p1, p2, layout = (2, 1))\n",
    "display(p)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The learned weights look perfect, let's check what happens if we use them to solve the GS model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparison: CNODE vs exact solutions"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "trange = (0.0, 600)\n",
    "dt, saveat = (1, 5)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exact solution"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "f_exact = create_f_CNODE((F_u, G_v), (grid_GS_u, grid_GS_v); is_closed = false);\n",
    "θ_e, st_e = Lux.setup(rng, f_exact);\n",
    "exact_CNODE = NeuralODE(f_exact,\n",
    "    trange,\n",
    "    Tsit5(),\n",
    "    adaptive = false,\n",
    "    dt = dt,\n",
    "    saveat = saveat);\n",
    "exact_CNODE_solution = Array(exact_CNODE(GS_sim[:, 1:2, 1], θ_e, st_e)[1]);\n",
    "u = reshape(exact_CNODE_solution[1:(grid_GS_u.N), :, :],\n",
    "    grid_GS_u.nx,\n",
    "    grid_GS_u.ny,\n",
    "    size(exact_CNODE_solution, 2),\n",
    "    :);\n",
    "v = reshape(exact_CNODE_solution[(grid_GS_v.N + 1):end, :, :],\n",
    "    grid_GS_v.nx,\n",
    "    grid_GS_v.ny,\n",
    "    size(exact_CNODE_solution, 2),\n",
    "    :);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Trained solution"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "trained_CNODE = NeuralODE(f_closed_CNODE,\n",
    "    trange,\n",
    "    Tsit5(),\n",
    "    adaptive = false,\n",
    "    dt = dt,\n",
    "    saveat = saveat);\n",
    "trained_CNODE_solution = Array(trained_CNODE(GS_sim[:, 1:2, 1], θ, st)[1]);\n",
    "u_trained = reshape(trained_CNODE_solution[1:(grid_GS_u.N), :, :],\n",
    "    grid_GS_u.nx,\n",
    "    grid_GS_u.ny,\n",
    "    size(trained_CNODE_solution, 2),\n",
    "    :);\n",
    "v_trained = reshape(trained_CNODE_solution[(grid_GS_u.N + 1):end, :, :],\n",
    "    grid_GS_v.nx,\n",
    "    grid_GS_v.ny,\n",
    "    size(trained_CNODE_solution, 2),\n",
    "    :);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Untrained solution"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "f_u = create_f_CNODE(\n",
    "    (F_u_open, G_v_open), (grid_GS_u, grid_GS_v), (NN_u, NN_v); is_closed = true)\n",
    "θ_u, st_u = Lux.setup(rng, f_u);\n",
    "untrained_CNODE = NeuralODE(f_u,\n",
    "    trange,\n",
    "    Tsit5(),\n",
    "    adaptive = false,\n",
    "    dt = dt,\n",
    "    saveat = saveat);\n",
    "untrained_CNODE_solution = Array(untrained_CNODE(GS_sim[:, 1:2, 1], θ_u, st_u)[1]);\n",
    "u_untrained = reshape(untrained_CNODE_solution[1:(grid_GS_u.N), :, :],\n",
    "    grid_GS_u.nx,\n",
    "    grid_GS_u.ny,\n",
    "    size(untrained_CNODE_solution, 2),\n",
    "    :);\n",
    "v_untrained = reshape(untrained_CNODE_solution[(grid_GS_v.N + 1):end, :, :],\n",
    "    grid_GS_v.nx,\n",
    "    grid_GS_v.ny,\n",
    "    size(untrained_CNODE_solution, 2),\n",
    "    :);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot the results"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "anim = Animation()\n",
    "fig = plot(layout = (2, 6), size = (1200, 400))\n",
    "@gif for i in 1:1:size(u_trained, 4)\n",
    "    # First row: set of parameters 1\n",
    "    p1 = heatmap(u[:, :, 1, i],\n",
    "        axis = false,\n",
    "        cbar = false,\n",
    "        aspect_ratio = 1,\n",
    "        color = :reds,\n",
    "        title = \"Exact\")\n",
    "    p2 = heatmap(v[:, :, 1, i],\n",
    "        axis = false,\n",
    "        cbar = false,\n",
    "        aspect_ratio = 1,\n",
    "        color = :blues)\n",
    "    p3 = heatmap(u_untrained[:, :, 1, i],\n",
    "        axis = false,\n",
    "        cbar = false,\n",
    "        aspect_ratio = 1,\n",
    "        color = :reds,\n",
    "        title = \"Untrained\")\n",
    "    p4 = heatmap(v_untrained[:, :, 1, i],\n",
    "        axis = false,\n",
    "        cbar = false,\n",
    "        aspect_ratio = 1,\n",
    "        color = :blues)\n",
    "    p5 = heatmap(u_trained[:, :, 1, i],\n",
    "        axis = false,\n",
    "        cbar = false,\n",
    "        aspect_ratio = 1,\n",
    "        color = :reds,\n",
    "        title = \"Trained\")\n",
    "    p6 = heatmap(v_trained[:, :, 1, i],\n",
    "        axis = false,\n",
    "        cbar = false,\n",
    "        aspect_ratio = 1,\n",
    "        color = :blues)\n",
    "\n",
    "    # Second row: set of parameters 2\n",
    "    p7 = heatmap(u[:, :, 2, i],\n",
    "        axis = false,\n",
    "        cbar = false,\n",
    "        aspect_ratio = 1,\n",
    "        color = :reds,\n",
    "        title = \"Exact\")\n",
    "    p8 = heatmap(v[:, :, 2, i],\n",
    "        axis = false,\n",
    "        cbar = false,\n",
    "        aspect_ratio = 1,\n",
    "        color = :blues)\n",
    "    p9 = heatmap(u_untrained[:, :, 2, i],\n",
    "        axis = false,\n",
    "        cbar = false,\n",
    "        aspect_ratio = 1,\n",
    "        color = :reds,\n",
    "        title = \"Untrained\")\n",
    "    p10 = heatmap(v_untrained[:, :, 2, i],\n",
    "        axis = false,\n",
    "        cbar = false,\n",
    "        aspect_ratio = 1,\n",
    "        color = :blues)\n",
    "    p11 = heatmap(u_trained[:, :, 2, i],\n",
    "        axis = false,\n",
    "        cbar = false,\n",
    "        aspect_ratio = 1,\n",
    "        color = :reds,\n",
    "        title = \"Trained\")\n",
    "    p12 = heatmap(v_trained[:, :, 2, i],\n",
    "        axis = false,\n",
    "        cbar = false,\n",
    "        aspect_ratio = 1,\n",
    "        color = :blues)\n",
    "\n",
    "    fig = plot(p1,\n",
    "        p2,\n",
    "        p3,\n",
    "        p4,\n",
    "        p5,\n",
    "        p6,\n",
    "        p7,\n",
    "        p8,\n",
    "        p9,\n",
    "        p10,\n",
    "        p11,\n",
    "        p12,\n",
    "        layout = (2, 6),\n",
    "        margin = 0mm)\n",
    "    frame(anim, fig)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the generated .gif"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "if isdir(\"./plots\")\n",
    "    gif(anim, \"./plots/02.02-trained_GS.gif\", fps = 10)\n",
    "else\n",
    "    gif(anim, \"examples/plots/02.02-trained_GS.gif\", fps = 10)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  },
  "kernelspec": {
   "name": "julia-1.10",
   "display_name": "Julia 1.10.3",
   "language": "julia"
  }
 },
 "nbformat": 4
}
